{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1998cead-4db8-426e-8e33-adb438b7aa34",
   "metadata": {},
   "source": [
    "# Day 7 – Web Scraping + Automation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaad46c-e298-4f73-8302-cfea4bf67fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1: Web Scraping with BeautifulSoup + requests\n",
    "# 1. What is Web Scraping?\n",
    "\n",
    "# Extracting data from websites automatically.\n",
    "\n",
    "# We use requests to fetch HTML code, and BeautifulSoup to parse it.\n",
    "# Tools:\n",
    "# requests: downloads the HTML of a webpage.\n",
    "\n",
    " # BeautifulSoup: parses (reads) the HTML and extracts useful parts (text, links, tables, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "025f30df-e990-4cc7-af2b-aa70c1069141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "\t<meta charset=\"UTF-8\">\n",
      "\t<title>Quotes to Scrape</title>\n",
      "    <link rel=\"stylesheet\" href=\"/static/bootstrap.min.css\">\n",
      "    <link rel=\"stylesheet\" href=\"/static/main.css\">\n",
      "    \n",
      "    \n",
      "</head>\n",
      "<body>\n",
      "    <div class=\"container\">\n",
      "        <div class=\"row header-box\">\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. Fetch a Webpage\n",
    "import requests\n",
    "url = \"https://quotes.toscrape.com/\"\n",
    "res = requests.get(url)  # send request to website\n",
    "print(res.status_code)     # 200 = success\n",
    "print(res.text[:300])     # show first 300 chars of HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4782d435-a6d0-4114-94d6-d62ec34ffbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation:\n",
    "\n",
    "# requests.get(url) fetches the webpage.\n",
    "\n",
    "# status_code 200 means request successful.\n",
    "\n",
    "# res.text contains full HTML code of the page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a34b7f1e-a922-44fd-ba8e-3b7f4d78ac11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quotes to Scrape\n",
      "\n",
      "Quotes to Scrape\n",
      "\n"
     ]
    }
   ],
   "source": [
    " # 3. Parse HTML with Beautifulsoup\n",
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup\n",
    "soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "print(soup.title.text)       # Title of page\n",
    "print(soup.find(\"h1\").text)  # First <h1> heading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdcfbc86-71dd-4e56-b10a-d454e47f6ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation:\n",
    "\n",
    "# BeautifulSoup(html, \"html.parser\") loads HTML into a structured object.\n",
    "\n",
    "# .title.text extracts text from <title> tag.\n",
    "\n",
    "# .find(\"h1\") finds the first <h1> element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66cf8181-9382-41d0-af94-94372f0d71cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quote: “The world as we have created it is a process of our thinking. It cannot be changed without changing our thinking.”\n",
      "Quote: “It is our choices, Harry, that show what we truly are, far more than our abilities.”\n",
      "Quote: “There are only two ways to live your life. One is as though nothing is a miracle. The other is as though everything is a miracle.”\n",
      "Author: Albert Einstein\n",
      "Author: J.K. Rowling\n",
      "Author: Albert Einstein\n"
     ]
    }
   ],
   "source": [
    "# 4. Extract Quotes & Authors\n",
    "# All quotes\n",
    "quotes = soup.find_all(\"span\", class_=\"text\")\n",
    "for q in quotes[:3]:\n",
    "    print(\"Quote:\", q.text)\n",
    "# All authors\n",
    "authors = soup.find_all(\"small\", class_=\"author\")\n",
    "for a in authors[:3]:\n",
    "    print(\"Author:\", a.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765ab9ca-8481-43c6-b7d6-80d3ca481e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation:\n",
    "\n",
    "# .find_all(\"span\", class_=\"text\") → all <span> tags with class=text.\n",
    "\n",
    "# .find_all(\"small\", class_=\"author\") → all author names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4eef91a9-2536-4a3b-8454-c1db49c6f068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      "/login\n",
      "/author/Albert-Einstein\n",
      "/tag/change/page/1/\n",
      "/tag/deep-thoughts/page/1/\n"
     ]
    }
   ],
   "source": [
    "# 5. Extract Links\n",
    "for link in soup.find_all(\"a\", href=True)[:5]:\n",
    "    print(link['href'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47e2726e-d2fa-45cd-9ec6-065af6b19817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation:\n",
    "\n",
    "# href=True → only anchor tags with href attribute.\n",
    "\n",
    "# link['href'] → gets the actual link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9d70fae-964f-4f0b-a526-3b02efab82f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next page link: /page/2/\n"
     ]
    }
   ],
   "source": [
    "# 6. Pagination (Next Page Link)\n",
    "next_page = soup.find(\"li\", class_=\"next\").a['href']\n",
    "print(\"Next page link:\", next_page)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5bdb492-1376-4f94-89da-58b87020e886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation:\n",
    "\n",
    "# Finds the <li class=\"next\"> → inside that, extracts <a href>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d1d9cd-a456-4274-9771-cae3d99f2ee7",
   "metadata": {},
   "source": [
    "# Part 2: Automation with os\n",
    "# 1. What is os?\n",
    "\n",
    "# Python module to interact with Operating System (folders, files, paths).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "468cfb86-0ebb-4377-badd-97e685d0dad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current directory: C:\\Users\\Acer Aspire 3\\internship work\n",
      "Files & Folders: ['.ipynb_checkpoints', 'backup', 'credits.csv', 'day 1.ipynb', 'Day 4.ipynb', 'ds_salaries.csv', 'eda-on-data-science-salaries.ipynb', 'keywords.csv', 'links.csv', 'links_small.csv', 'movies_metadata.csv', 'plot.pdf', 'plot.png', 'plot_0.png', 'plot_1.png', 'plot_2.png', 'quotes.csv', 'ratings.csv', 'ratings_small.csv', 'salaries.csv', 'salaries.json', 'test.txt', 'test_folder', 'week 3.ipynb', 'week 6.ipynb', 'week 7.ipynb']\n"
     ]
    }
   ],
   "source": [
    "# 2. Common Functions\n",
    "import os\n",
    "print(\"current directory:\", os.getcwd()) # Get current directory\n",
    "os.mkdir(\"test_folder\")                   # Create new folder\n",
    "print(\"Files & Folders:\", os.listdir())   # List files & folders\n",
    "os.rename(\"test_folder\", \"renamed_folder\")  # Rename folder\n",
    "os.rmdir(\"renamed_folder\")                  # Remove empty folder \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82ec86d1-73c7-4d74-ae87-d6c76fdfa61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current directory: C:\\Users\\Acer Aspire 3\\internship work\n",
      "Files & Folders: ['.ipynb_checkpoints', 'backup', 'credits.csv', 'day 1.ipynb', 'Day 4.ipynb', 'ds_salaries.csv', 'eda-on-data-science-salaries.ipynb', 'keywords.csv', 'links.csv', 'links_small.csv', 'movies_metadata.csv', 'plot.pdf', 'plot.png', 'plot_0.png', 'plot_1.png', 'plot_2.png', 'quotes.csv', 'ratings.csv', 'ratings_small.csv', 'salaries.csv', 'salaries.json', 'test.txt', 'test_folder', 'week 3.ipynb', 'week 6.ipynb', 'week 7.ipynb']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(\"Current directory:\", os.getcwd())   # Get current directory\n",
    "os.mkdir(\"test_folder\")                    # Create new folder\n",
    "print(\"Files & Folders:\", os.listdir())    # List files & folders\n",
    "os.rename(\"test_folder\", \"renamed_folder\") # Rename folder\n",
    "os.rmdir(\"renamed_folder\")                 # Remove empty folder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c323af36-8b1d-4988-b128-ab10abf86742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation:\n",
    "\n",
    "# os.getcwd() → shows where the script runs.\n",
    "\n",
    "# os.mkdir() → makes folder.\n",
    "\n",
    "# os.listdir() → shows files/folders inside.\n",
    "\n",
    "# os.rename() → renames folder/file.\n",
    "\n",
    "# os.rmdir() → removes empty folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3b0ffb5c-5908-42f9-8273-609f9ed3839e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scraped_data\\quotes.csv\n"
     ]
    }
   ],
   "source": [
    "# 3. File Path Handling\n",
    "file_path = os.path.join(\"scraped_data\", \"quotes.csv\")\n",
    "print(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a87d45a-4811-479e-b514-780be23803f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation:\n",
    "\n",
    "# os.path.join() builds safe file paths (works on Windows/Linux)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb17a0c-b1bc-4c93-8f62-ad64ca18d688",
   "metadata": {},
   "source": [
    "# Part 3: Automation with shutil\n",
    "# 1. What is shutil?\n",
    "\n",
    "# High-level file operations (copy, move, delete)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1caca4b7-c95c-4f21-bf85-01600151315e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scraped_data/backup.ccsv'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Common Functions\n",
    "import shutil, os\n",
    "# ensure folder + file exist\n",
    "os.makedirs(\"scraped_data\", exist_ok=True)\n",
    "with open(\"scraped_data/quotes.csv\", \"w\") as f:\n",
    "    f.write(\"quote_author\\nSample quote,Author\")\n",
    "#copy file\n",
    "shutil.copy(\"scraped_data/quotes.csv\", \"backup.csv\")\n",
    "# move file\n",
    "shutil.move(\"backup.csv\", \"scraped_data/backup.ccsv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "25c22bd0-2007-4a2a-b79b-615e4d48583f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation:\n",
    "\n",
    "# shutil.copy(src, dst) → copy file.\n",
    "\n",
    "# shutil.move(src, dst) → move file.\n",
    "\n",
    "# shutil.rmtree(folder) → delete folder (careful!)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328739ba-da6f-4465-ac4f-a290579fcd2f",
   "metadata": {},
   "source": [
    "# Part 4: Mini Project – Scrape Quotes & Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1fbb6248-ceef-44e2-a656-38a7220a4bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quotes saved to quotes.csv\n",
      "Backup created successfully!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import os, shutil\n",
    "# step 1: scrape quotes\n",
    "url = \"https://quotes.toscrape.com/\"\n",
    "res = requests.get(url)\n",
    "soup = BeautifulSoup(res.text, \"html.parser\")\n",
    "quotes = []\n",
    "for box in soup.find_all(\"div\", class_=\"quote\"):  \n",
    "    text = box.find(\"span\", class_=\"text\").text\n",
    "    author = box.find(\"small\", class_=\"author\").text\n",
    "    quotes.append({\"quote\": text, \"author\":author})\n",
    "# Step 2: Save to CSV\n",
    "with open(\"quotes.csv\", \"w\", newline='',encoding=\"utf-8\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"quote\", \"author\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(quotes)\n",
    "print(\"quotes saved to quotes.csv\")\n",
    "# Step 3: Organize with os\n",
    "if not os.path.exists(\"scraped_data\"):\n",
    "    os.mkdir(\"scraped_data\")\n",
    "os.replace(\"quotes.csv\", os.path.join(\"scraped_data\", \"quotes.csv\"))    \n",
    "# Step 4: Backup with shutil    \n",
    "if not os.path.exists(\"backup\"):\n",
    "    os.mkdir(\"backup\")\n",
    "shutil.copy(\"scraped_data/quotes.csv\", \"backup/quotes_backup.csv\")\n",
    "print(\"Backup created successfully!\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f351398f-5e82-4983-b0dd-2c4ff3d8192e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explanation:\n",
    "\n",
    "# Scraping: Extracts quotes + authors.\n",
    "\n",
    "# CSV writing: Saves structured data.\n",
    "\n",
    "# os: Creates folder & moves file into scraped_data/.\n",
    "\n",
    "# shutil: Copies file into backup/ for safety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3c13b2-f8b6-4dbd-8157-82064e8e8c90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43392f05-3d5d-4fbc-8ca9-fb9cb057ab3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d431ccd-4388-4f3d-b8a1-d64a54ce9a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2904d716-adb0-4afe-8a70-adefc83e652a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
